---
title: "Untitled"
author: "Filippo Maganza"
date: "10/2/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


# Non-parametric methods

Non-parametric methods allow inference without making the assumption that the sample has been taken from a particular distribution. Therefore, they can applied in a vastely range of samples, for example when the assumptions of common parametric methods do not hold.

## Permutation test

The permutation test, introduced by R. A. Fisher in the 1930s, is used to check the hypothesis that the two groups being compared have identical distributions. The idea of the test is to build the distribution of the test statistic under the null hypothesis by calculating all possible values of the test statistic under rearrangements of the group labels on the observed data points.

Even under normality but unequal variances, the method fails to control the probability of a Type I error when testing the hypothesis of equal means (e.g., Boik, 1987).


### Assumptions
*. Exchangeability


### Procedure of the test

Let $X_a = (X_{1a},...,X_{n_aa})$ and $X_2 = (X_{1b},...,X_{n_bb})$ be two samples drawn respectively from the population of group $a$ and from population of group $b$. Let $X_a = (X_{1a},...,X_{n_aa},X_{1b},...,X_{n_bb})$ be the pooled sample. Given the null hyphothesis $H_O: X_1=_dX_2$:

1. Compute the oberved test statistic $T(X) = S(X_a) âˆ’ S (X_b)$ where $S$ is a symmetric (i.e. invariant with respect to the order of sample elements) and monotonic function such that large values of $T$ are evidence against $H_0$. A typical example of S is the sample mean.
2. Build the null reference distribution by computing the test statistic in 1 with all permutations of group label assignments.
3. Compute the p-value using $H_A$.


### Examples
<!-- Let $X_1$ be a random variable representing one population and $X_2$ the random variable representing another population. We can then formally define the following test: -->
<!-- $H_O: X_1=_dX_2 \;\;\;\; H_A: X_1>_dX_2$ -->
<!-- Here $=_d$ denotes $F_1(x)=F_2(x) \;\; \forall x \in  R_{X_1,X_2}$ and means "is equal in distribution to", and $>_d$ denotes $F_1(x)\leq F_2(x) \;\; \forall x \in  R_{X_1,X_2}$ (first-order stochastic dominance). -->

### R algorithms

```{r, echo = TRUE}
T.test=function(x1,x2,alt,K=1000)
     {x=c(x1,x2)
      n1=length(x1)
      n2=length(x2)
      n=n1+n2
      t.ob=sum(x1)-sum(x2)
      t.perm=vector(,K)

      for (k in 1:K)
         {x.perm=sample(x)
          x1.perm=x.perm[1:n1]
          x2.perm=x.perm[(n1+1):(n1+n2)]
          t.perm[k]=sum(x1.perm)-sum(x2.perm)
         }
    
      if (alt=="greater")   pv.t=length(t.perm[t.perm>=t.ob])/K
      if (alt=="less")      pv.t=length(t.perm[t.perm<=t.ob])/K
      if (alt=="two.sided") pv.t=length(abs(t.perm)[abs(t.perm)>=abs(t.ob)])/K

     print(pv.t)
}

x1=rnorm(3)
x2=rnorm(3)
T.test(x1,x2,"two.sided",10000)

T.test2=function(x1,x2,alt) {
  library(combinat)
  
  x=c(x1,x2)
  n1=length(x1)
  n2=length(x2)
  n=n1+n2
  t.ob=sum(x1)-sum(x2)
  permutations = permn(x)
  t.perm=vector(,length(permutations))
  
  for (i in length(permutations)) {
    x1.perm=permutations[[i]][1:n1]
    x2.perm=permutations[[i]][(n1+1):(n1+n2)]
    t.perm[i]=sum(x1.perm)-sum(x2.perm)
  }
  
  if (alt=="greater")   pv.t=length(t.perm[t.perm>=t.ob])/length(permutations)
  if (alt=="less")      pv.t=length(t.perm[t.perm<=t.ob])/length(permutations)
  if (alt=="two.sided") pv.t=length(abs(t.perm)[abs(t.perm)>=abs(t.ob)])/length(permutations)
  
  print(pv.t)
}

```

## The tri-aspect test

## Wilcoxon test
The Wilcoxon rank-sum test is just a permutation test on ranks R(Xij) rather than on Xij.

## Lepage test

## Cucconi test

Cucconi test is a nonparametric test for jointly comparing central tendency and variability (detecting location and scale changes) in two samples.

### Applicability

Location-scale tests

### Test statistic

### Null reference distribution

# Properties of statistical tests

## Exactness
Using an exact test provides a significance test that keeps the Type I error rate of the test ($\alpha) at the desired significance level of the test.



