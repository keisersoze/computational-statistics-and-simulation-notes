---
title: "Untitled"
author: "Filippo Maganza"
date: "10/2/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Hyphotesis Testing Problems

## Two sample indetical distributions problem
Let $X_a = (X_{1a},...,X_{n_aa})$ and $X_2 = (X_{1b},...,X_{n_bb})$ be two samples drawn respectively from the population of group $a$ and from population of group $b$. Let $X_a = (X_{1a},...,X_{n_aa},X_{1b},...,X_{n_bb})$ be the pooled sample. 

The problem consists in testing:

$H_O: X_1=_dX_2$: against $H_O: X_1\neq_dX_2$ (two-sided)

## Two-sample location problem
Let be $X_1 = (X_{11},...,X_{1n_1})$ and $X_2 = (X_{21},...,X_{2n_2})$ independent random samples taken from populations with continuous distribution functions that may differ only in their locations $\mu_1$
and $\mu_2$; let $n_1+n_2=n$.

The problem consists in testing:

$H_O: \mu_1 - \mu_2 = 0$ against $H_A: \mu_1 - \mu_2 \neq  0$

## Two-sample location scale problem
Let be $X_1 = (X_{11},...,X_{1n_1})$ and $X_2 = (X_{21},...,X_{2n_2})$ independent random samples taken from populations with continuous distribution functions that may differ only in their locations $\mu_1$
and $\mu_2$ and variances $\sigma_1$and $\sigma_2$.

The problem consists in testing:

$H_O: \{\mu_1 = \mu_2 \cap \sigma_1 = \sigma_2\}	$ against $H_A: \{\mu_1 \neq \mu_2 \cap \sigma_1 \neq \sigma_2\}$

# Non-parametric methods

Non-parametric methods allow inference without making the assumption that the sample has been taken from a particular distribution. Therefore, they can applied in a vastely range of samples, for example when the assumptions of common parametric methods do not hold.

Parametric tests act exclusively within the population model, which is based on a hypothetical population with a specific distribution and of usually infinite size from which the samples are randomly drawn.

## Permutation test and permutation testing

The permutation test, introduced by R. A. Fisher in the 1930s, is used to check the hypothesis that the two groups being compared have identical distributions. The idea of the test is to build the distribution of the test statistic under the null hypothesis by calculating all possible values of the test statistic under rearrangements of the group labels on the observed data points. Even under normality but unequal variances, the method fails to control the probability of a Type I error when testing the hypothesis of equal means (e.g., Boik, 1987).

Permutation testing is also an abstract statistical procedure for hypothesis testing in which one calculates the values that the test statistic T assumes on the observed data and the all permutations of the data to decide whether to accept or reject the null hypothesis. In other words permutation testing can be used to obtain the distribution of the test statistic under the null hypothesis  by calculating all possible values of the test statistic under all possible rearrangements of the observed data points.

### Abstract procedure

1. Compute the oberved test statistic $T(X) = S(X_a) âˆ’ S (X_b)$ where $S$ is a symmetric (i.e. invariant with respect to the order of sample elements) and monotonic function such that large values of $T$ are evidence against $H_0$. Typical choices of $T$ includes:
  * $T(X) = \sum_{i=1}^{n_1} X_{i} - \sum_{i=n_1 + 1}^{n} X_{i}$ ( equivalent to  $T_a = \frac{1}{n}\sum_{i=1}^{n_1} X_{i} - \frac{1}{n - n_1}\sum_{i=n_1 + 1}^{n} X_{i}$)
  * $T_c(X) = \sum_{i=1}^{n_1} R(X_{i}) - \sum_{i=n_1 + 1}^{n} R(X_{i})$, where R is the rank function.
2. Build the null reference distribution by computing the test statistic in 1 with all permutations of group label assignments. Alternatively, the null reference distribution can be estimated by taking only $k$ random permutations.
3. Compute the p-value or the estimated p-value using $H_A$. For example, if the problem we are considering is 
  * 
  
Computational burden: the number of permuations is ${n_1  + n_2 \choose n_1} = \frac{(n_1 + n_2)!}{n_1!n_!}$.

Properties of p-value estimator: when $k$ is large, the p-value estimator is approximately normally distributed with mean $p$ and variance $p(1-p)/k$.

### Assumptions
* Exchangeability (under the null)

### Applicability 
The permutation test can be many applied to [Problem 0] and [Two-sample location problem].

### Examples
<!-- Let $X_1$ be a random variable representing one population and $X_2$ the random variable representing another population. We can then formally define the following test: -->
<!-- $H_O: X_1=_dX_2 \;\;\;\; H_A: X_1>_dX_2$ -->
<!-- Here $=_d$ denotes $F_1(x)=F_2(x) \;\; \forall x \in  R_{X_1,X_2}$ and means "is equal in distribution to", and $>_d$ denotes $F_1(x)\leq F_2(x) \;\; \forall x \in  R_{X_1,X_2}$ (first-order stochastic dominance). -->

### R algorithms

```{r, echo = TRUE}
T.test=function(x1,x2,alt,K=1000)
     {x=c(x1,x2)
      n1=length(x1)
      n2=length(x2)
      n=n1+n2
      t.ob=sum(x1)-sum(x2)
      t.perm=vector(,K)

      for (k in 1:K)
         {x.perm=sample(x)
          x1.perm=x.perm[1:n1]
          x2.perm=x.perm[(n1+1):(n1+n2)]
          t.perm[k]=sum(x1.perm)-sum(x2.perm)
         }
    
      if (alt=="greater")   pv.t=length(t.perm[t.perm>=t.ob])/K
      if (alt=="less")      pv.t=length(t.perm[t.perm<=t.ob])/K
      if (alt=="two.sided") pv.t=length(abs(t.perm)[abs(t.perm)>=abs(t.ob)])/K

     print(pv.t)
}

x1=rnorm(3)
x2=rnorm(3)
T.test(x1,x2,"two.sided",10000)

permutation.test=function(x1,x2,testStatistic,alt) {
  library(combinat)
  
  x=c(x1,x2)
  n1=length(x1)
  n2=length(x2)
  n=n1+n2
  t.ob=sum(x1)-sum(x2)
  x1.perm.indexes.array = combn(seq(1,n), n1)
  nperm = ncol(x1.perm.indexes.array)
  t.perm=vector(,nperm)
  
  for (i in 1:nperm) {
    x1.perm.indexes = x1.perm.indexes.array[,i]
    x2.perm.indexes = setdiff(seq(1,n), x1.perm.indexes)
    x1.perm = x[x1.perm.indexes]
    x2.perm = x[x2.perm.indexes]
    t.perm[i]=testStatistic(x1.perm,x2.perm)
  }
  
  if (alt=="greater")   pv.t=length(t.perm[t.perm>=t.ob])/nperm
  if (alt=="less")      pv.t=length(t.perm[t.perm<=t.ob])/nperm
  if (alt=="two.sided") pv.t=length(abs(t.perm)[abs(t.perm)>=abs(t.ob)])/nperm
  
  return(pv.t)
}

statistics.differenceOfSums = function(x1,x2){
  return(sum(x1)-sum(x2))
}

x1=rnorm(10)
x2=rnorm(10, mean = 1)
print(permutation.test(x1,x2,statistics.differenceOfSums,"two.sided"))

```

## The bi-aspect and tri-aspect tests
The permutation test for the [Two-sample location problem] take into consideration only the quantitative aspect $X_i$ of sample units and thus may be seen as uni-aspect tests. The $T_{ab}$ test is a nonparametric test for the same problem which considers also the categorical aspect $Z_i = I(X_i>M)$, where $M$ denotes the sample median. The two aspects are addressed respectively by:
* The $T_a$ test: $T_a = \sum_{i=1}^{n_1} X_{i} - \sum_{i=n_1 + 1}^{n} X_{i}$
* The $T_b$ test: $T_b = \sum_{i=1}^{n_1} Z_{i} - \sum_{i=n_1 + 1}^{n} Z_{i}$

The $T_a$ test
* is generally effective with regular, roughly symmetric,
unimodal, and light-tailed distributions, whereas it is not effective with highly asymmetric and/or heavy-tailed
distributions
* is not consistent for distributions for which the first and second moments do not exist

The $T_b$ test
* is much more powerful for detecting location shifts under highly-asymmetric and/or heavy-tailed distributions.
* is consistent for every distribution

The T_{abc} test extends the T_{ab} test by including a third aspect in the combination, the rank aspect $W_i = \sum_{j=1}^{n}{I(X_i \geo X_j)}$. This third aspect is adressed by the $T_c$ test $T_c = \sum_{i=1}^{n_1} W_{i} - \sum_{i=n_1 + 1}^{n} W_{i}$. Although $T_b$ is better than $T_c$ for some distributions like the double-exponential and the Cauchy, $T_c$ is better than $T_b$ with most distributions including the normal.

# Applicability

Can be many applied to the [Two-sample location problem].

## Wilcoxon rank-sum test

The Wilcoxon rank-sum test is just a permutation test on ranks R(X_{i}) rather than on X_{i}.

# Applicability 

## Lepage test
Lepage test is a nonparametric test for the  [Two-sample location scale problem] which is based on the combination of two tests, one for location and another for scale. The combination is achieved through the sum of the squared standardized Wilcoxon-Mann-Whitney and Ansari-Bradley statistics:

## Cucconi test

Cucconi test is a nonparametric test for the  [Two-sample location scale problem] which is not  familiar as other location-scale tests but it is of interest for several reasons:
* from a historical point of view it is of interest because it has been
proposed some years before the Lepage test.
* it is not a combination of a test for location and a test for scale as
the other location-scale tests.

### Applicability

Location-scale tests

### Test statistic

### Null reference distribution

# Properties of statistical tests

## Exactness
Using an exact test provides a significance test that keeps the Type I error rate of the test ($\alpha) at the desired significance level of the test.



